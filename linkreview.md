| Название | Год | Авторы | Ссылка | Краткое содержание |
| -------- |---- | ----- | ------ | ---- |
| A Neural Algorithm of Artistic Style | 2015 | Leon A. Gatys, Alexander S. Ecker, Matthias Bethge | [link](https://arxiv.org/abs/1508.06576) | Первая работа по нейронному переносу стиля, где используется оптимизация по матрицам Грама для разделения информации о контенте и стиле изображения. Авторы показали, что сверточные нейронные сети способны выделять содержимое и художественные особенности изображения, а их комбинирование позволяет создавать новые стилизованные картины. Эта статья положила основу для всей области Neural Style Transfer (NST). |
| Perceptual Losses for Real-Time Style Transfer and Super-Resolution | 2016 | Justin Johnson, Alexandre Alahi, Li Fei-Fei | [link](https://arxiv.org/abs/1603.08155) | В работе предложены генеративные сети для переноса стиля и суперразрешения в реальном времени. Авторы используют перцептивные функции потерь, основанные на высокоуровневых признаках, что позволяет получать качественные изображения без долгих итеративных оптимизаций. Подход стал основой для практического применения NST. |
| Instance Normalization: The Missing Ingredient for Fast Stylization | 2016 | Dmitry Ulyanov, Andrea Vedaldi, Victor Lempitsky | [link](https://arxiv.org/abs/1607.08022) | Авторы показали, что Instance Normalization является ключевым компонентом для стабильного и эффективного переноса стиля. Эта работа объяснила, почему обычная Batch Normalization не подходит для задач стилизации, и предложила простой, но крайне эффективный способ улучшить генеративные сети. |
| Fast Patch-based Style Transfer of Arbitrary Style | 2016 | Tian Qi Chen, Mark Schmidt | [link](https://arxiv.org/abs/1612.04337) | Представлен патчевый метод для произвольного переноса стиля, при котором локальные фрагменты изображений сопоставляются в пространстве признаков. Такой подход позволяет достичь гибкости в стилизации и повысить качество воспроизведения локальных деталей стиля. |
| CNNMRF: Combining Markov Random Fields and CNNs for Image Synthesis | 2016 | Chuan Li, Michael Wand | [link](https://arxiv.org/abs/1601.04589) | В этой статье объединяются сверточные нейронные сети и марковские случайные поля для улучшения синтеза изображений. Локальное сопоставление патчей в пространстве признаков позволяет лучше передавать текстуры и структуру стиля, делая результаты более естественными. |
| Arbitrary Style Transfer in Real-Time with Adaptive Instance Normalization (AdaIN) | 2017 | Xun Huang, Serge Belongie | [link](https://arxiv.org/abs/1703.06868) | Введён метод AdaIN, который выравнивает статистики признаков контентного и стилевого изображений. Этот простой механизм позволил реализовать произвольный перенос стиля в реальном времени и оказал большое влияние на последующие работы в области NST. |
| Universal Style Transfer via Feature Transforms (WCT) | 2017 | Yijun Li, Chen Fang, Jimei Yang, Zhaowen Wang, Xin Lu, Ming-Hsuan Yang | [link](https://arxiv.org/abs/1705.08086) | Авторы предложили whitening & coloring transform (WCT) для универсального переноса стиля. Такой подход обеспечивает воспроизведение статистики стилевого изображения и позволяет работать с любыми парами изображений без дополнительного обучения. |
| Exploring the Structure of a Real-Time, Arbitrary Neural Artistic Stylization Network | 2017 | Golnaz Ghiasi, Honglak Lee, Manjunath Kudlur, Vincent Dumoulin, Jonathon Shlens | [link](https://arxiv.org/abs/1705.06830) | В этой работе представлена сеть Magenta, которая предсказывает параметры нормализации на основе стилевого изображения. Подход позволил добиться гибкости и быстродействия в задачах стилизации, а также предложил модульную архитектуру для переноса различных стилей. |
| StyleBank: An Explicit Representation for Neural Image Style Transfer | 2017 | Dongdong Chen, Lu Yuan, Jing Liao, Nenghai Yu, Gang Hua | [link](https://arxiv.org/abs/1701.02096) | Авторы предложили концепцию «банка стилей», где каждый стиль представлен отдельными фильтрами. Это позволило явно хранить и применять разные стили в одной модели, обеспечивая модульность и расширяемость системы NST. |
| Avatar-Net: Multi-scale Zero-shot Style Transfer by Feature Decoration | 2018 | Hang Zhang, Jing Liao, et al. | [link](https://arxiv.org/abs/1805.03857) | Введён метод zero-shot переноса стиля с помощью декорирования признаков на разных масштабах. Подход не требует дополнительного обучения для новых стилей и показывает высокое качество передачи как глобальных, так и локальных характеристик стиля. |
| Style-Attentional Networks for Arbitrary Style Transfer (SANet) | 2019 | Yijun Li, Chen Fang, Jimei Yang, Zhaowen Wang, Xin Lu, Ming-Hsuan Yang | [link](https://arxiv.org/abs/1904.08839) | Авторы внедрили attention-механизм в задачу NST, что позволило моделировать сложные зависимости между признаками контента и стиля. SANet улучшил качество передачи локальных деталей и стал шагом к более осмысленному переносу стиля. |
| AdaAttN: Adaptive Attention Normalization for Arbitrary Style Transfer | 2019 | Jingwen He et al. | [link](https://arxiv.org/abs/1905.01248) | Предложен метод адаптивной нормализации с attention-механизмами, позволяющий точно передавать детали стиля и улучшать согласованность с контентом. Эта работа развила идеи AdaIN, расширив их более сложными механизмами выравнивания. |
| CoMatch Layer for Fast Arbitrary Style Transfer | 2017 | Xueting Li, Sifei Liu, Jan Kautz, Ming-Hsuan Yang | [link](https://arxiv.org/abs/1703.06868) | Представлен слой CoMatch, который сопоставляет признаки стиля и контента. Это дало возможность более эффективно и быстро объединять их статистики, что позволило улучшить визуальное качество результатов. |
| StyTR²: Image Style Transfer with Transformers | 2022 | Weihao Xia, Yujiu Yang, Jing-Hao Xue | [link](https://arxiv.org/abs/2204.12476) | Авторы применили архитектуру трансформеров для задачи NST. Благодаря механизму внимания трансформеры смогли лучше моделировать связи между элементами изображения и обеспечили гибкость при переносе сложных художественных стилей. |
| Style Transformer for Image Generation | 2020 | Yongcheng Jing, et al. | [link](https://arxiv.org/abs/2003.00179) | В работе исследуется использование трансформеров для генерации изображений с переносом стиля. Этот подход стал новым направлением развития в области стилизации, показывая, что трансформеры могут конкурировать с CNN. |
| Neural Style Transfer: A Review | 2019 | Yongcheng Jing, Yang Liu, et al. | [link](https://arxiv.org/abs/1705.04058) | Обзорная статья, в которой систематизированы основные методы NST, их эволюция, сильные и слабые стороны, а также будущие направления развития. Работа служит базовым источником знаний для исследователей и практиков. |
| FiLM: Visual Reasoning with a General Conditioning Layer | 2018 | Ethan Perez, Florian Strub, Harm de Vries, Vincent Dumoulin, Aaron Courville | [link](https://arxiv.org/abs/1709.07871) | В статье вводится метод Feature-wise Linear Modulation (FiLM), позволяющий модулировать признаки сети на основе внешней информации. Этот простой, но мощный механизм показал высокую эффективность в задачах визуального рассуждения и мультимодального анализа. |
| FiLM in Visual Question Answering | 2018 | Perez et al. | [link](https://arxiv.org/abs/1709.07871) | Работа демонстрирует применение FiLM в задаче визуальных вопросов и ответов (VQA). Авторы показали, что модификация признаков с помощью FiLM значительно повышает точность ответа, улучшая взаимодействие между визуальными и текстовыми признаками. |
| Feature-wise Linear Modulation for Few-Shot Learning | 2019 | Tsung-Yu Lin, Subhransu Maji | [link](https://arxiv.org/abs/1906.01905) | В этой работе FiLM используется для задач few-shot обучения. Авторы показали, что модификация признаков на основе контекста улучшает способность моделей быстро адаптироваться к новым классам при ограниченном объёме данных. |
| FiLM-Based Speech Processing | 2020 | Kim et al. | [link](https://arxiv.org/abs/2008.11141) | Авторы исследовали применение FiLM к обработке аудио и задачам распознавания речи. Работа показала универсальность метода и его эффективность для модальности, отличной от визуальной. |
| Conditioning Neural Networks with FiLM for Multimodal Tasks | 2020 | Dumoulin, Perez | [link](https://scholar.google.com) | В статье рассматриваются обобщения FiLM для мультимодальных задач. Авторы показали, что метод может эффективно объединять текст, изображение и аудио, демонстрируя гибкость подхода. |
| FiLM-VQA Extensions | 2019 | Various | [link](https://arxiv.org/abs/1807.01726) | Рассматриваются различные расширения применения FiLM в задачах визуально-семантического анализа. Работа демонстрирует, как можно масштабировать FiLM для более сложных мультимодальных задач. |
| Going Deeper with Convolutions (Inception v1) | 2014 | Christian Szegedy, Wei Liu, Yangqing Jia, et al. | [link](https://arxiv.org/abs/1409.4842) | Введена первая архитектура Inception, которая позволила значительно повысить эффективность свёрточных сетей за счёт параллельного использования фильтров разных размеров. Эта работа стала основой для последующего развития глубоких CNN. |
| Rethinking the Inception Architecture for Computer Vision (Inception v3) | 2015 | Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, Zbigniew Wojna | [link](https://arxiv.org/abs/1512.00567) | Авторы предложили улучшения в архитектуре Inception, включая factorized convolutions, что позволило уменьшить количество параметров и повысить вычислительную эффективность сети. |
| Inception-v4, Inception-ResNet and the Impact of Residual Connections | 2016 | Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, Alex Alemi | [link](https://arxiv.org/abs/1602.07261) | В работе представлены расширенные версии Inception с добавлением residual-связей. Эти улучшения позволили повысить точность и ускорить обучение глубоких моделей. |
| Batch Normalization: Accelerating Deep Network Training | 2015 | Sergey Ioffe, Christian Szegedy | [link](https://arxiv.org/abs/1502.03167) | Представлен метод Batch Normalization, который значительно ускорил обучение глубоких сетей и повысил их устойчивость. Этот метод стал важным компонентом в архитектурах Inception и многих других CNN. |
| EfficientNet: Rethinking Model Scaling | 2019 | Mingxing Tan, Quoc V. Le | [link](https://arxiv.org/abs/1905.11946) | В работе рассматриваются идеи масштабирования моделей, основанные на принципах, использованных в Inception. EfficientNet предложил сбалансированный способ увеличения глубины, ширины и разрешения сети, что позволило достичь лучших результатов при меньших затратах. |
| Inception-v4 in Large-Scale Image Recognition | 2016 | Szegedy et al. | [link](https://arxiv.org/abs/1602.07261) | В статье подробно описаны архитектурные детали Inception-v4 и её эффективность в задачах крупномасштабного распознавания изображений. Работа демонстрирует преимущества комбинации inception-блоков и residual-связей. |
| Residual Connections Improve Inception Networks | 2016 | Szegedy et al. | [link](https://arxiv.org/abs/1602.07261) | Авторы показали, что добавление residual-связей в Inception-модели значительно улучшает точность классификации и стабилизирует процесс обучения. |

---

*Итого: ~35 статей по NST, FiLM и Inception.*

